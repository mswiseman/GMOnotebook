{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *GMOdetector notebook*: Template to analyze a new batch of images\n",
    "**Notebook template for applying routine hyperspectral/segmentation cross-analysis phenomics workflow over new datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v.0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/WorkflowFlowchart.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workflow, images taken with the macroPhor Array dual RGB/hyperspectral imaging platform are analyzed by a workflow in which regression quantifies fluorescent signals in hyperspectral images, deep learning segments RGB images into different tissues, and these datasets are cross-referenced to produce statistics on growth of transgenic callus and shoot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for use\n",
    "1.  Enter information for the experiment below\n",
    "2. Set <font color=blue>variables</font> for data paths and parameters, as instructed by colored boxes.\n",
    "3. \"Save as\" with filename describing experiment and anything special about this analysis (e.g. T18_OD_TAO_wk7_automation_test_attempt2.ipynb)\n",
    "4. Run notebook from console, by either one of two methods:\n",
    "- In the top bar of JupyterLab, select \"Run\" and \"Run all cells\"\n",
    "- In a terminal, enter the below command with the notebook filename inserted<br>\n",
    "```jupyter nbconvert --to HTML --ExecutePreprocessor.timeout=-1 --allow-errors --execute insert_filename_here```\n",
    "5. Wait for email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment ID and quick description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Provide a short description of the experiment in the below box. This should include unique identifier codes for the experiment, along with a short description of genotypes and treatments studied. The timepoint should also be included. </div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset (Phase ID and week timepoint): \"GTW_wk10\"\n",
    "\n",
    "This notebook comes from a template which we use in R scripts to automatically generate a notebook for each \n",
    "transformation GWAS phase x timepoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Parameters for analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The below variables must be modified appropriately every time this workflow is run over new images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data location\n",
    "The `data` variable below provides the **complete** path to the folder containing data to be analyzed. This should include all folders and subfolders in which the data of interest is organized by. For the organizational system used for our lab's data, this should follow the format \"/Experiment/Subexperiment/Timepoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix=\"/media//gmobot/easystore/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_suffix=\"GWAS_Transformation/GTW/wk10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"${data_prefix}${data_suffix}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample information\n",
    "Every experiment has a randomization datasheet, which was used to organize treatment and genotype information for each plate, prepare labels, and randomize plates. The path to this file is provided through the `randomization_datasheets` variable below. This workflow requires this datasheet in order to know which plates have which genotype/treatment. At a later date, we will integrate an ability to read this data directly from labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomization_datasheet=\"/home/gmobot/GMOnotebook/Transformation_GWAS/Randomization_datasheets//GTW_32_genotypes_labels.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection of missing or contaminated explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `missing_explants` variable to `\"Automatic\"` if using model to automatically detect missing and contaminated explants. Note that this model is only supported for plates with 12 explants. Otherwise, provide an appropriately formatted `.csv` spreadsheet (see example)  of manually scored contamination / missing explant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_explants=\"Automatic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your email where results will be sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email=michael.nagle@oregonstate.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "All variables below should be modified only as needed to indicate the fluorescent proteins in samples and the grid layout of explants. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluorescent protein settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below should be all known fluorescent components contained in the sample. This includes each fluorescent protein, as well as a \"noise\" or \"diffraction\" term if applicable. All of these components must exist in the user's spectral library. `GMOdetector` currently comes with a spectral library that includes, by default:\n",
    "- DsRed\n",
    "- ZsYellow\n",
    "- GFP\n",
    "- Chl\n",
    "- ChlA\n",
    "- ChlB\n",
    "- Diffraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluorophores=(GFP Chl Diffraction) # An explanation of array variables in bash is here: https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_10_02.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user has the option of limiting loading of hyperspectral data and subsequent regression to a specific range of wavelengths, using the `desired_wavelength_range` array variable. This range should cover all fluorophores provided in the `fluorophores` array variable able. Aside from runtime, there is no disadvantage to including a wider range than is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_wavelength_range=(500 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False color plot settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assist user inspection of regression results, false color plots can be produced by `GMOdetector` to show results of regression over whole samples. \n",
    "Note: In v0.2.0.x of the workflow, these parameters are independent of those used later by `GMOlabeler` to produce by-explant plots including false color plots. These will be made the same in a later update.\n",
    "The `FalseColor_channels` array variable indicates the components to be plotted as red, green and blue, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseColor_channels=(Chl GFP Diffraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FalseColor_caps` array variable indicates an upper limit of signal for each of these component. Any signal at or above these values will appear with maximum brightness; thus, these variables are comparable to exposure on a camera. If caps are too high, not much signal at lower ranges will be seen. If cap for a given component is too low, the false color images will appear overexposed with respect to the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseColor_caps=(200 400 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GMOlabeler` will use the below parameters to classify individual explants on plates as positive for a given fluorescent protein or not. A single fluorescent protein is chosen for the by-explant false color plots. Multiple can be used to generate the final plots summarizing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporters=(GFP Chl)\n",
    "#reporter=DsRed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for reporter signal threshold and pixel threshold must be provided by the user. Our grid search yielded several noted below. These were most recently calculated from statistics produced with Python `GMOdetector`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/GMOlabeler_parameters.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter_threshold=38\n",
    "pixel_threshold=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, `GMOlabeler` distinguishes explants by their expected position on a plate. This is supported for plates with 12 or 20 explants, arranged in specific positions on a grid. False positives may result in cases in which one explant grows to such an extent that it intrudes into the grid square meant for an adjacent explant. <br>In the future, an additional neural network will be used to segment individual explants on a per-pixel basis, avoiding the need for crude cropping, and the outputs from the resulting model will be integrated with `GMOlabeler`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping to grid squares is supported for standard grids with 12 or 20 explants, as indicated by the `grid` variable. An image of each grid square (with a file path provided by the `grid_file` variable) will be superimposed over each image during `GMOlabeler` analysis to allow the user to easily inspect and verify grid positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define grid borders for the grid with an image size of 2000x2000, not yet aligned to hyperspectral images. These borders will be used for the contamination model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_aligned_resized_grid_borders=(\"230,469.5,1688,1584\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define grid borders for the grid after alignment. If unsure what to use, you may wish to wait until after alignment and inspection of results to set this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_grid_borders=\"98 1254 1228 280\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "The below variables do not need to be modified during any routine use of the workflow.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following variables, use 0 (False) or 1 (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dimensions for plot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#width=15\n",
    "width=9\n",
    "height=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set to \"Automatic\" if generating a new homography matrix from the grid standard included in the data folder. If using an existing homography matrix, enter the name here. This file should be in the \"output\" subfolder of the path to the `ImageAlignment` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homography=\"Automatic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set to \"Automatic\" or the path to the hyperspectral channel used to produce the homography matrix provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypercube_csv=\"Automatic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to be used for generating a homography  matrix; these will only be used if `homography` is set to \"Automatic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance=0.66\n",
    "gaussian_sigma=0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set to \"Automatic\" or the path to the jpg resulting from using the homography matrix (indicated by the `homography` variable) above to transform the original grid jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_grid=\"Automatic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_align_each_img=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths to workflow modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These only need to be modified if you are setting up a `GMOnotebook` template on a new computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=\"/home/gmobot/GMOnotebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodetector_wd=\"/home/gmobot/gmodetector_py/\"\n",
    "spectral_library_path=\"${gmodetector_wd}spectral_library/\"\n",
    "deeplab_path=\"/home/gmobot/poplar_model_2_w_contam/\"\n",
    "alignment_path=\"/home/gmobot/ImageAlignment/\"\n",
    "gmolabeler_path=\"/home/gmobot/GMOlabeler/\"\n",
    "contamination_path=\"/home/gmobot/DenseNet\"\n",
    "data_prefix=\"/home/gmobot/data/\"\n",
    "output_directory_prefix=\"${data_prefix}gmodetector_out/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "With all above variables set, please \"Save as...\" with a filename referencing this specific dataset. <br>Finally, deploy the workflow (Step 4 in above instructions).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated workflow to be deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the below code for a walkthrough of how GMOnotebook works, or view the outputs after running the workflow for help troubleshooting errors in specific steps of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Danger:</b> Do not modify any below code without creating a new version of the template notebook. During routine usage, this workflow should be customized only by modifying variables above, while leaving the below code unmodified. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These internal variables are set automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp=$(date +”%Y-%m-%d”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder=$(echo $data | cut -d/ -f5-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint=\"$(basename -- $data_folder)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_full=\"$output_directory_prefix$data_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_name=$(echo $data_folder | sed -e 's/\\//-/g')\n",
    "dataset_name=$(echo $data_folder | sed -e 's/\\///g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time analysis begins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantification of fluorescent proteins by regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python package `CubeGLM` is used to quantify fluorescent proteins in each pixel of hyperspectral images via linear regression. Hyperspectral images are regressed over spectra of known components, and pixelwise maps of test-statistics are constructed for each component in the sample. This approach to quantifying components of hyperspectral images is described in-depth in the Methods section from <a href=\"https://link.springer.com/article/10.1007/s40789-019-0252-7\" target=\"_blank\">Böhme, et al. 2019</a>. Code and documentation for `CubeGLM` is on <a href=\"https://github.com/naglemi/GMOdetector_py\" target=\"_blank\">Github</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $gmodetector_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list_name=\"$dataset_name.jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf $job_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in $data/*.hdr\n",
    "do\n",
    " if [[ \"$file\" != *'hroma'* ]] && [[ \"$file\" != *'roadband'* ]]; then\n",
    "  echo \"python -W ignore wrappers/analyze_sample.py \\\n",
    "--file_path $file \\\n",
    "--fluorophores ${fluorophores[*]} \\\n",
    "--min_desired_wavelength ${desired_wavelength_range[0]} \\\n",
    "--max_desired_wavelength ${desired_wavelength_range[1]} \\\n",
    "--red_channel ${FalseColor_channels[0]} \\\n",
    "--green_channel ${FalseColor_channels[1]} \\\n",
    "--blue_channel ${FalseColor_channels[2]} \\\n",
    "--red_cap ${FalseColor_caps[0]} \\\n",
    "--green_cap ${FalseColor_caps[1]} \\\n",
    "--blue_cap ${FalseColor_caps[2]} \\\n",
    "--plot 1 \\\n",
    "--spectral_library_path \"$spectral_library_path\" \\\n",
    "--output_dir $output_directory_full \\\n",
    "--threshold 38\" >> $job_list_name\n",
    " fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $job_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conda activate cubeglm\n",
    "\n",
    "if [ $parallel -eq 1 ]\n",
    "then\n",
    "    parallel -a $job_list_name\n",
    "fi\n",
    "\n",
    "if [ $parallel -eq 0 ]\n",
    "then\n",
    "    bash $job_list_name\n",
    "fi\n",
    "\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time regression completes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks to segment tissues, classify missing/contaminated explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic segmentation of tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are segmented into specific plant tissues by a deep neural network of the state-of-the-art Deeplab v3 architecture <a href=\"https://arxiv.org/abs/1706.05587\" target=\"_blank\">Liang-Chieh et al., 2017</a>. The model has been trained using training sets generated with our annotation GUI Intelligent DEep Annotator for Segmentation (IDEAS, available on <a href=\"https://bitbucket.org/JialinYuan/image-annotator/src/master/\" target=\"_blank\">Bitbucket</a>, publication pending). Our branch of the Deeplab v3 repo, including a Jupyter walkthrough for training, can be found on Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is completed upstream of this notebook, which only entails analysis of test data using the latest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/downsized/segmentation_composite2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: This example image was taken from an experiment on the effects of different CIMs on cottonwood regeneration. This composite image illustrates that for every sample, tissues are segmented into stem (red), callus (blue) and shoot (green). These composite images, useful for manual inspection of results, are produced when the 'composite' option is on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We desire for images to all be in the same orientation. At one point, the camera on the *macroPhor Array* was set to automatically detect orientation, which led to images randomly being in portrait or landscape. Here we will standardize the orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate alignment\n",
    "for filename in $data/*.jpg; do\n",
    "    exiftool -Orientation=8 -n $filename > ${data}log_exiftool.txt\n",
    "    done\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f $data/*original*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crop and resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script resizes images to 900x900 and then crops away top and bottom 150 pixels for a final image size of 900x600."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose for cropping is to remove labels, which has been standard practice for all training and testing. Otherwise, we could run into problems such as the neural network \"learning\" plants labeled as control have more or less regeneration.<br>The purpose for resizing is to reduce computational expense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ${cwd}/intermediates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate base\n",
    "python crop.py $data\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare input list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script `inference.py` requires a list of all files to be analyzed. We will create this file as `test.csv`. This will be a list of all our (pre-processed) image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data\n",
    "ls -d $PWD/* $data | grep -i \"rgb_cropped.jpg\" > test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the chroma standard from list of RGB image data to be segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed -i '/hroma/d' \"${data}/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model is deployed to perform semantic segmentation of experimental images. A list of RGB images to be segmented by the trained model is passed through the --image-list option. For each of these images, we will obtain an output mask (.png) of labeled tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `opencv`, `scipy`, `yaml` and `tensorflow` (version 1.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd $deeplab_path\n",
    "conda activate deeplab\n",
    "export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "python -W ignore deeplab/inference.py \\\n",
    "--image_lists \"${data}/test.csv\" \\\n",
    "--crop_size 900 --crop_size 600 \\\n",
    "--seg_results segmentation_results \\\n",
    "--model_dir \"${deeplab_path}/deeplab/model/\"\n",
    ">> $data/log_inference.txt\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ls \"${deeplab_path}/segmentation_results/output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up and reorganize files. Let's keep the outputs we need with all other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv \"${deeplab_path}/segmentation_results/raw/\"* $data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name outputs to reflect that they are segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data\n",
    "for file in *_rgb_cropped.png; do mv -f \"$file\" \"${file%_rgb_cropped.png}_segment_cropped.png\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-expand segment outputs to same size as original RGB files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `scikit-image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate alignment\n",
    "#cd ${cwd}/intermediates\n",
    "cd $alignment_path\n",
    "python expand.py $data >> $data/log_expand.txt\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date # started abt 5:15pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make composite images with side-by-side RGB, segmentation outputs and blended images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate test-environment\n",
    "# if [ $composite -eq 1 ]\n",
    "# then\n",
    "#     cd $gmolabeler_path\n",
    "#     python image_blender.py $data 0.75 'both' 1 180 >> $data/log_blend.txt\n",
    "# fi\n",
    "# conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of contaminated/missing explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plates are cropped into sub-images for each explant and each is analyzed to determine if the explant position should be excluded from analysis due to being missing or contamination. Missing and contaminated explants are recognized using a trained Densenet model (<a href=\"https://github.com/Contamination-Classification/DenseNet\" target=\"_blank\">Huang, et al. 2018</a>). Our fork of the Densenet repository is available on <a href=\"https://arxiv.org/abs/1608.06993\" target=\"_blank\">GitHub</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Densenet.png\">\n",
    "Figure: These are four examples of contaminated explants used in the training set for this pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the grid cropping dimensions, we can run the following script. Note that these are the dimensions to crop the image to after resizing to 2000x2000 (from 4000x4000 in the case of the *macroPhor Array)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $missing_explants = \"Automatic\" ]; then\n",
    "    echo \"Missing explants will be inferred.\"\n",
    "    cd $data\n",
    "    ls -d $PWD/* $data | grep -i \"rgb.jpg\" > rgb_list.txt\n",
    "    sed -i '/hroma/d' rgb_list.txt\n",
    "    img_list_path=\"${data}/rgb_list.txt\"\n",
    "else\n",
    "    echo \"Missing explants input manually by user, in file: \"\n",
    "    echo $missing_explants\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mode for missing explant data is automatic, prepare input file for script to detect missing explants and run this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check dimensions for grid cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models to detect contamination and missing explants require a user input to define the pixel boundaries of the grid along which explants are placed. Note that currently, only the 12-explant grid is supported. To use other grids, contamination and missing explant data must be provided manually in a file formatted just like an output from this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running `inference.py` to detect missing or contaminated explants, the user should provide dimensions for cropping down to the grid borders. Note, these dimensions apply after the image is rescaled to 2000x2000.\n",
    "- Default dimensions, used before the imager began to take \"off-center\" images, are (310, 515, 1750, 1610).\n",
    "- Dimensions for cropping for the off-center images are (260, 600, 1700, 1710). \n",
    "- New dimensions (275, 438, 1725, 1535) are for images taken after camera settings were re-centered.<br>\n",
    "\n",
    "We can test dimensions using the `--debug` option for `inference.py` as in the below code block. Next, we will run the same script in the regular mode to detect missing and contaminated explants using settled-upon cropping dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run this code block only if you wish to troubleshoot cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if [ $missing_explants = \"Automatic\" ]; then\n",
    "#     cd $contamination_path\n",
    "#     conda activate densenet\n",
    "#     python inference.py --img-list=$img_list_path --crop_dims \"(275,438,1725,1535)\" --debug\n",
    "#     conda deactivate\n",
    "# else\n",
    "#     echo \"Missing explants input manually by user, in file: \"\n",
    "#     echo $missing_explants\n",
    "# fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs will be saved in this folder and can be evaluated to check how well the cropping worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo $contamination_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer contaminated/missing explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `keras-preprocessing`, `termcolor`,  `protobuf` and `absl-py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if [ $missing_explants = \"Automatic\" ]; then\n",
    "    cd $contamination_path\n",
    "    conda activate DenseNet\n",
    "    python -W ignore inference.py \\\n",
    "    --img-list=$img_list_path \\\n",
    "    --crop_dims $pre_aligned_resized_grid_borders \\\n",
    "    --output_file=output.csv >> $data/log_contam.txt\n",
    "    mv -f output.csv \"${data}/output.csv\"\n",
    "    conda deactivate\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $missing_explants = \"Automatic\" ]; then\n",
    "    missing_explants=\"${data}/output.csv\"\n",
    "    echo \"Missing explants inferred by model and written to file:\"\n",
    "    echo $missing_explants\n",
    "else\n",
    "    echo \"Missing explants input manually by user, in file: \"\n",
    "    echo $missing_explants\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of RGB and hyperspectral layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> This section of the workflow must be run regardless of whether a homography matrix for alignment has been provided or will be generated.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the frame and angle of RGB and hyperspectral image layers, we apply a scale-invariant feature transformation (<a href=\"https://github.com/NSF-Image-alignment/ImageAlignment\" target=\"_blank\">GitHub</a>). Using a pair of standard images, a homography matrix is calculated for the necessary transformation of RGB images to align with hyperspectral images. The transformation can then be applied to large batches of images rapidly, as long as the RGB and hyperspectral cameras remain in the same positions relative to one another (as they do in the macroPhor Array platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Alignment.png\">\n",
    "Figure: To enable precise calculation of a homography matrix for transformation of RGB images to match hyperspectral images, we used images of a piece of paper with grid marks. These images are provided by the user inputs to --hyper-img and --rgb-img in the below call to the alignment script. If using a phenotyping platform other than the macroPhor Array, or using updated camera settings, these variables will need to be replaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare file lists for alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> We will produce two lists: one for hyperspectral channels (chlorophyll peak channel) for each sample and another for the complementary RGB images. We will superimpose them and produce images for inspection, allowing the user to make sure the alignment works reliably for all images. However, it is possible to replace the hyperspectral channels for each image with a single file; this would run more quickly but be less useful for allowing the user to validate alignment results.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to produce a csv with two columns with headers `hyper_img` and `rgb_images`. For each RGB image being transformed in batch alignment (mode 2), we can test the alignment by producing superimposed images of the transformed RGB images together with a hyperspectral layer. The hyperspectral layer can either be for a grid (fast) or can be for a layer extracted from the hyperspectral image of each channel (slow, but useful for making sure a certain homography matrix works reliably to transform a batch of images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first generate the list that will go into the column `rgb_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data\n",
    "ls | grep -i 'rgb\\.jpg' > file_list_part1.csv\n",
    "ls | grep -i 'segment_uncropped\\.png' > file_list_part2.csv\n",
    "cat file_list_part* > file_list.csv\n",
    "# sed -i '/hroma/d' file_list.csv\n",
    "cwd2=$(pwd)/\n",
    "awk -v prefix=\"$cwd2\" '{print prefix $0}' file_list.csv > temp\n",
    "mv -f temp file_list.csv\n",
    "echo 'rgb_images' | cat - file_list.csv > temp && mv -f temp file_list.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If testing alignment on every image, we will now modify the list going into the `rgb_images` column to produce the list of filenames for `hyper_img`. If not, we will simply use the `_hyperchannel.csv` file for every value of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_align_each_img=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if [ $test_align_each_img -eq 1 ]; then\n",
    "cp file_list.csv file_list_hyper_channel.csv\n",
    "sed -i 's/_rgb.jpg/_hyperchannel.csv/g' file_list_hyper_channel.csv\n",
    "sed -i 's/rgb_images/hyper_img/g' file_list_hyper_channel.csv\n",
    "sed -i 's/_segment_uncropped.png/_hyperchannel.csv/g' file_list_hyper_channel.csv\n",
    "paste --delimiters=',' file_list_hyper_channel.csv file_list.csv > rgb_and_hyper_channel_lists.csv\n",
    "#fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if [ $test_align_each_img -eq 0 ]; then\n",
    "#Rscript $cwd/intermediates/generate_file_list_with_grid.R\n",
    "#fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a homography matrix for alignment if one is not provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> This section is only needed if a homography matrix has not been provided and must be generated. In this section, a hyperspectral channel is extracted from the standard to be used for alignment with the complementary RGB image.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using this method, we should have RGB and hyperspectral images of a grid. Here, we will assume they have \"grid\" in their name and can be found in the same folder as the sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate a homography matrix for alignment of the grid images (RGB and hyperspectral) because these align more robustly than images of plants. We will then apply this homography matrix to alignment of all RGB plant images, so that they will align with the respective hyperspectral images. Note, for this approach to work the relative positions and angles of RGB/hyperspectral cameras must be the same for all image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data$grid_hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $alignment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $grid_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $homography = \"Automatic\" ]; then\n",
    "    grid_hdr=$(ls $data | grep -i \"grid\" | grep -i \"Fluorescence.hdr\")\n",
    "    grid_jpg=$(ls $data | grep -i \"grid\" | grep -i \"rgb.jpg\")\n",
    "    echo \"Homography matrix to be generated by alignment of:\"\n",
    "    echo $grid_hdr\n",
    "    echo $grid_jpg\n",
    "    conda activate cubeglm\n",
    "    cd $alignment_path\n",
    "    python hypercube_to_csv.py \\\n",
    "    $data$grid_hdr \\\n",
    "    700 \\\n",
    "    130 \\\n",
    "    $data\"hypercube_to_csv.csv\" \\\n",
    "    $data\"hypercube_to_csv.jpg\"\n",
    "    conda deactivate\n",
    "    aligned_grid=$(echo $grid_jpg | sed 's/rgb/rgb_aligned/g')\n",
    "    aligned_grid=${alignment_path}output/$aligned_grid\n",
    "    conda activate alignment\n",
    "    cd $alignment_path\n",
    "    python main.py \\\n",
    "    --hyper-img $data\"hypercube_to_csv.csv\" \\\n",
    "    --rgb-img $data$grid_jpg \\\n",
    "    --mode 1 \\\n",
    "    --image_thresh_high=120 \\\n",
    "    --image_thresh_low=50 \\\n",
    "    --distance=$distance \\\n",
    "    --gaussian_sigma=$gaussian_sigma\n",
    "    conda deactivate\n",
    "    homography=$(echo $grid_jpg | sed 's/\\.jpg/_homography.npy/g')\n",
    "    homography=${alignment_path}output/$homography\n",
    "    hypercube_csv=\"${data}hypercube_to_csv.csv\"\n",
    "else\n",
    "    echo \"Homography matrix provided by user at:\"\n",
    "    echo ${gmolabeler_path}output/$homography\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save copies of the homography matrix and aligned images for later inspection and reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_subfolder_name=$(echo $data_folder | sed -e 's/\\//_/g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $alignment_subfolder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p $cwd/existing_alignments/$alignment_subfolder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $hypercube_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $aligned_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp $homography $cwd/existing_alignments/$alignment_subfolder_name\n",
    "cp $hypercube_csv $cwd/existing_alignments/$alignment_subfolder_name\n",
    "cp $aligned_grid $cwd/existing_alignments/$alignment_subfolder_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> We can visualize the extracted hyperspectral channel to make sure there is a signal and everything looks good.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data\"hypercube_to_csv.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> We can also inspect the alignment to make sure image layers stack and align well.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $aligned_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display < $aligned_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate `csv` of hyperspectral channel for every image in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is optional. It is useful to *make sure* the alignment works reasonably well for every image, but it can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $test_align_each_img -eq 1 ]; then\n",
    "hdr_files=$data/*.hdr\n",
    "cd $alignment_path\n",
    "conda activate cubeglm\n",
    "for hdr_file in $hdr_files\n",
    "do\n",
    " csv_file=$(sed 's/Fluorescence.hdr/hyperchannel.csv/g' <<< $hdr_file)\n",
    " csv_file=$(sed 's/.hdr/_hyperchannel.csv/g' <<< $csv_file)\n",
    " csv_jpg=$(sed 's/csv/jpg/g' <<< $csv_file)\n",
    " python -W ignore hypercube_to_csv.py \\\n",
    " $hdr_file \\\n",
    " 300 \\\n",
    " 219 \\\n",
    " $csv_file \\\n",
    " $csv_jpg >> ${data}log_hypercube2csv.txt\n",
    "done\n",
    "conda deactivate\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run batch alignment to apply homography matrix to all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $hypercube_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head \"${data}/rgb_and_hyper_channel_lists.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate alignment\n",
    "cd $alignment_path\n",
    "file_list_input=\"${data}/rgb_and_hyper_channel_lists.csv\"\n",
    "python main.py \\\n",
    "--hyper-img $hypercube_csv \\\n",
    "--img-csv $file_list_input \\\n",
    "--mode 2 \\\n",
    "--h_matrix_path $homography >> $data/log_alignment_mode2.txt\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-analyze deep segmentation and regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts in the <a href=\"https://github.com/naglemi/GMOlabeler\" target=\"_blank\">GMOlabeler repository</a> are used to cross-reference results from deep segmentation of RGB images and regression of hyperspectral imaging, apply thresholding parameters to classify tissues as transgenic or escapes, and produce plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/GMOlabeler.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: The various steps of data processing in GMOlabeler are illustrated for an example explant from an experiment on CIM optimization for cottonwood. Images of plates are cropped to a sub-image for each explant. RGB segmentation results and hyperspectral regression results are cross-referenced to calculate fluorecent proteins in specific tissues and infer whether these tissues are transgenic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample datasheet input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input file we will use for making plots. This file contains paths to CLS results, RGB images, and hyperspectral images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "cd \"${cwd}/intermediates/\"\n",
    "Rscript pre_label.R \\\n",
    "-r \"${data}/\" \\\n",
    "-R \"${output_directory_prefix}\" \\\n",
    "-i 1 \\\n",
    "-d $datestamp\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-reference RGB and hyperspectral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On 1/11/20, we altered `gmolabeler` to accept user-defined borders of the grid box, rather than hardcoding these borders in for specific grids with 12 or 20 explants. Thus, if providing `grid_borders`, `grid` can be left as `None`, or vice versa. To determine the borders, open the *aligned* grid file in a GUI like GIMP or Microsoft Paint and use the crosshairs to find the pixel positions of each border. These are then provided through the `grid_borders` parameter in order \"top bottom right left\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on grid copping parameters:\n",
    "- Submit a space-delimited string with parameters for borders of grid as \"left right bottom top\"\n",
    "- For FAA wk3, use parameters \"139 1580 1250 312\"\n",
    "- For FAA wk7 and FAD wk7, use \"156 1600 1280 335\"\n",
    "- For all images taken after re-centering of camera settings on 1/18/21, use \"152 1592 1200 260\" if images are of high resolution (2GB hyperspectral files) or \"110 1356 1168 222\" if of normal resolution (1.3GB hyperspectral files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo ${data}/samples_pre_labeling.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $aligned_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head $data/samples_pre_labeling.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $aligned_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $reporters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reporter in ${reporters[@]}; do\n",
    "    echo $reporter\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "cd $gmolabeler_path\n",
    "for reporter in ${reporters[@]}; do\n",
    "    python main.py \\\n",
    "    \"${data}/samples_pre_labeling.csv\" \\\n",
    "    $aligned_grid \\\n",
    "    $reporter_threshold \\\n",
    "    $reporter \\\n",
    "    $grid \\\n",
    "    \"hdf\" \\\n",
    "    $gmolabeler_path \\\n",
    "    \"$aligned_grid_borders\" > $data/log_gmolabeler_$reporter.txt\n",
    "done\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sums of statistics over combined segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in all regenerated tissue (callus + shoot) as well as all tissue (including stem as well). We will calculate aggregate statistics over these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "for reporter in ${reporters[@]}; do\n",
    "    Rscript calculate_sum_stats_over_combined_segments.R \\\n",
    "    --output_dir \"${gmolabeler_path}/output/\" \\\n",
    "    --datapath \"${data_folder}/${reporter}/\"\n",
    "done\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plots of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "cd $gmolabeler_path\n",
    "for reporter in ${reporters[@]}; do\n",
    "    Rscript grid_item_plots.R \\\n",
    "    -d \"${data_folder}/\" \\\n",
    "    -r \"$randomization_datasheet\" \\\n",
    "    -p $pixel_threshold \\\n",
    "    -v categorical \\\n",
    "    -m 1 \\\n",
    "    -M $missing_explants \\\n",
    "    -g $grid \\\n",
    "    --samples-pre-labeling ${data}/samples_pre_labeling.csv \\\n",
    "    --sort 1 \\\n",
    "    --height $height \\\n",
    "    --width $width \\\n",
    "    --Reporter $reporter\n",
    "done\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $randomization_datasheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email plots to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZIP results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"${gmolabeler_path}/plots${data_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"${gmolabeler_path}/plots/${data_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f ./plants_over_plates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo ${gmolabeler_path}/output/${data_folder}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp \"${gmolabeler_path}/output/${data_folder}/plants_over_plates.csv\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reporter in ${reporters[@]}; do\n",
    "    cp \"${gmolabeler_path}/output/${data_folder}/${reporter}/stats_with_sums_over_tissues.csv\" ./\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f Rplots.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This messy substitution is explained here: https://superuser.com/questions/1068031/replace-backslash-with-forward-slash-in-a-variable-in-bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_Compress=\"${data_folder////-}.zip\"\n",
    "data_folder_Compress=${data_folder_Compress#?};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data_folder_Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd $timepoint\n",
    "zip -r $data_folder_Compress ./*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration=$(( SECONDS - start ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://unix.stackexchange.com/questions/53841/how-to-use-a-timer-in-bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f \"${gmolabeler_path}/email_to_send.txt\"\n",
    "cp \"${gmolabeler_path}/email_to_send_template.txt\" \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "echo \"Number of samples run: \" >> \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat \"${data}/test.csv\" | wc -l >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "echo \"\" >> \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (( $SECONDS > 3600 )) ; then\n",
    "    let \"hours=SECONDS/3600\"\n",
    "    let \"minutes=(SECONDS%3600)/60\"\n",
    "    let \"seconds=(SECONDS%3600)%60\"\n",
    "    echo \"Completed in $hours hour(s), $minutes minute(s) and $seconds second(s)\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "elif (( $SECONDS > 60 )) ; then\n",
    "    let \"minutes=(SECONDS%3600)/60\"\n",
    "    let \"seconds=(SECONDS%3600)%60\"\n",
    "    echo \"Completed in $minutes minute(s) and $seconds second(s)\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "else\n",
    "    echo \"Completed in $SECONDS seconds\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"\" >> \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send email with results to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data_folder_Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data_folder_Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"s-nail -a $data_folder_Compress -s $data_folder $email < \"${gmolabeler_path}/email_to_send.txt\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s-nail -a $data_folder_Compress -s $data_folder $email < \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du -sh $data_folder_Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time workflow ends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"tst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
