{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *GMOnotebook*\n",
    "#### **Notebook template for applying routine hyperspectral/segmentation cross-analysis phenomics workflow over new datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notebook template v0.2.03 (Oct 14, 2020)\n",
    "###### v0.2.0 onward applies the Python `GMOdetector` package instead of the deprecated R `GMOdetectoR` package, for much faster runtime\n",
    "###### v0.2.01 has calls to `conda` cleaned up with `conda activate` and `conda deactivate` in the same code blocks to avoid any problems with warnings/errors preventing automatic execution of subsequent blocks\n",
    "###### v0.2.02 is cleaned up using path variables (declared in notebook) instead of hardcoded paths, for portability\n",
    "###### v0.2.03 is more clean to avoid running alignment-processed images through `inference.py` if an analysis if being repeated... also has better instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v.0.2.05 is updated to work with FAA wk7. Specifically, there are updates to deal with increased image resolution (y~=2000), off-center images, and rotated images, including metadata normalization and user inputs for parameterized grid cropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/WorkflowFlowchart.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workflow, images taken with the macroPhor Array dual RGB/hyperspectral imaging platform are analyzed by a workflow in which regression quantifies fluorescent signals in hyperspectral images, deep learning segments RGB images into different tissues, and these datasets are cross-referenced to produce statistics on growth of transgenic callus and shoot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions for use\n",
    "1.  Enter information for the experiment below\n",
    "2. Set <font color=blue>variables</font> for data paths and parameters, as instructed by colored boxes.\n",
    "3. \"Save as\" with filename describing experiment and anything special about this analysis (e.g. T18_OD_TAO_wk7_automation_test_attempt2.ipynb)\n",
    "4. Run notebook from console, by either one of two methods:\n",
    "- In the top bar of JupyterLab, select \"Run\" and \"Run all cells\"\n",
    "- In a terminal, enter the below command with the notebook filename inserted<br>\n",
    "```jupyter nbconvert --to HTML --ExecutePreprocessor.timeout=-1 --allow-errors --execute insert_filename_here```\n",
    "5. Wait for email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment ID and quick description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Provide a short description of the experiment in the below box. This should include unique identifier codes for the experiment, along with a short description of genotypes and treatments studied. The timepoint should also be included. </div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FAB: Testing new DEV gene plasmids\n",
    "Week 7 timepoint – After 3w callus induction and 4w shoot induction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The below variables must be modified appropriately every time this workflow is run over new images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data location\n",
    "The `data` variable below provides the **complete** path to the folder containing data to be analyzed. This should include all folders and subfolders in which the data of interest is organized by. For the organizational system used for our lab's data, this should follow the format \"/Experiment/Subexperiment/Timepoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix=\"/run/media/labgroup/Elements_9/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"${data_prefix}/Transformation/FAB_Dev_Genes/wk7/Fluorescent/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample information\n",
    "Every experiment has a randomization datasheet, which was used to organize treatment and genotype information for each plate, prepare labels, and randomize plates. The path to this file is provided through the `randomization_datasheets` variable below. This workflow requires this datasheet in order to know which plates have which genotype/treatment. At a later date, we will integrate an ability to read this data directly from labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomization_datasheet=\"/run/media/labgroup/Elements_9/Transformation/FAD_Dev_Genes/FAD_randomization_list_labels.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exclusion of missing/contaminated explants from analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `missing_explants` variable to `\"Automatic\"` if using model to automatically detect missing and contaminated explants. Note that this model is only supported for plates with 12 explants. Otherwise, provide an appropriately formatted `.csv` spreadsheet (see example)  of manually scored contamination / missing explant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_explants=\"Automatic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your email where results will be sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email=michael.nagle@oregonstate.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "All variables below should be modified only as needed to indicate the fluorescent proteins in samples and the grid layout of explants. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Provide information pertinent to the fluorophores in the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below should be all known fluorescent components contained in the sample. This includes each fluorescent protein, as well as a \"noise\" or \"diffraction\" term if applicable. All of these components must exist in the user's spectral library. `GMOdetector` currently comes with a spectral library that includes, by default:\n",
    "- DsRed\n",
    "- ZsYellow\n",
    "- GFP\n",
    "- Chl\n",
    "- ChlA\n",
    "- ChlB\n",
    "- Diffraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluorophores=(DsRed Chl Diffraction) # An explanation of array variables in bash is here: https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_10_02.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user has the option of limiting loading of hyperspectral data and subsequent regression to a specific range of wavelengths, using the `desired_wavelength_range` array variable. This range should cover all fluorophores provided in the `fluorophores` array variable able. Aside from runtime, there is no disadvantage to including a wider range than is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_wavelength_range=(500 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To assist user inspection of regression results, false color plots will be produced by `GMOdetector` to show results of regression over whole samples. \n",
    "###### Note: In v0.2.0 of the workflow, these parameters are independent of those used later by `GMOlabeler` to produce by-explant plots including false color plots. These will be made the same in a later update.\n",
    "The `FalseColor_channels` array variable indicates the components to be plotted as red, green and blue, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseColor_channels=(Chl DsRed Diffraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FalseColor_caps` array variable indicates an upper limit of signal for each of these component. Any signal at or above these values will appear with maximum brightness; thus, these variables are comparable to exposure on a camera. If caps are too high, not much signal at lower ranges will be seen. If cap for a given component is too low, the false color images will appear overexposed with respect to the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseColor_caps=(200 400 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `GMOlabeler` will use the below parameters to classify individual explants on plates as transgenic or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reporter=GFP\n",
    "reporter=DsRed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for reporter signal threshold and pixel threshold must be provided by the user. Our grid search yielded several noted below. These were most recently calculated from statistics produced with Python `GMOdetector`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/GMOlabeler_parameters.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter_threshold=38\n",
    "pixel_threshold=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, `GMOlabeler` distinguishes explants by their expected position on a plate. This is supported for plates with 12 or 20 explants, arranged in specific positions on a grid. False positives may result in cases in which one explant grows to such an extent that it intrudes into the grid square meant for an adjacent explant. <br>In the future, an additional neural network will be used to segment individual explants on a per-pixel basis, avoiding the need for crude cropping, and the outputs from the resulting model will be integrated with `GMOlabeler`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping to grid squares is supported for standard grids with 12 or 20 explants, as indicated by the `grid` variable. An image of each grid square (with a file path provided by the `grid_file` variable) will be superimposed over each image during `GMOlabeler` analysis to allow the user to easily inspect and verify grid positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "The below variables do not need to be modified during any routine use of the workflow.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following variables, use 0 (False) or 1 (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dimensions for plot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#width=15\n",
    "width=9\n",
    "height=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths to workflow components on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=\"/home/labgroup/code/GMOnotebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gmodetector_wd=\"/scratch2/NSF_GWAS/notebooks/gmodetector_py/\"\n",
    "gmodetector_wd=\"/home/labgroup/code/gmodetector_py/\"\n",
    "spectral_library_path=\"${gmodetector_wd}spectral_library/\"\n",
    "#output_directory_prefix=\"/scratch2/NSF_GWAS/gmodetector_out/\"\n",
    "#deeplab_path=\"/scratch2/NSF_GWAS/deeplab/\"\n",
    "deeplab_path=\"/home/labgroup/code/deeplab/\"\n",
    "#alignment_path=\"/scratch2/NSF_GWAS/ImageAlignment/\"\n",
    "alignment_path=\"/home/labgroup/code/ImageAlignment/\"\n",
    "#gmolabeler_path=\"/scratch2/NSF_GWAS/GMOlabeler/\"\n",
    "gmolabeler_path=\"/home/labgroup/code/GMOlabeler/\"\n",
    "#contamination_path=\"/scratch2/NSF_GWAS/Contamination\"\n",
    "contamination_path=\"/home/labgroup/code/DenseNet\"\n",
    "data_prefix=\"/home/labgroup/data/\"\n",
    "output_directory_prefix=\"${data_prefix}gmodetector_out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_file=\"/scratch2/NSF_GWAS/macroPhor_Array/grids/grid20_post_processed.png\"\n",
    "#grid_file=\"/scratch2/NSF_GWAS/macroPhor_Array/grids/grids_left_facing_125208_1_0_1_rgb_processed.jpg\"\n",
    "\n",
    "# For data from before when imager went off-center\n",
    "# grid_file=\"${gmolabeler_path}/grids/grid_12_explants_left-facing_processed.jpg\"\n",
    "\n",
    "# For offcenter images\n",
    "grid_file=\"${alignment_path}/output/chromagrid_I5.0_F1.9_L100_122503_0_0_0_rgb_aligned.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "With all above variables set, please \"Save as...\" with a filename referencing this specific dataset. <br>Finally, deploy the workflow (Step 4 in above instructions).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated workflow to be deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the below code for a walkthrough of how GMOnotebook works, or view the outputs after running the workflow for help troubleshooting errors in specific steps of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Danger:</b> Do not modify any below code without creating a new version of the template notebook. During routine usage, this workflow should be customized only by modifying variables above, while leaving the below code unmodified. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These internal variables are set automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp=$(date +”%Y-%m-%d”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder=$(echo $data | cut -d/ -f5-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint=\"$(basename -- $data_folder)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_full=\"$output_directory_prefix$data_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=$(echo $data_folder | sed -e 's/\\//-/g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time analysis begins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quantification of fluorescent proteins by regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python package `GMOdetector` is used to quantify fluorescent proteins in each pixel of hyperspectral images via linear regression. Hyperspectral images are regressed over spectra of known components, and pixelwise maps of test-statistics are constructed for each component in the sample. This approach to quantifying components of hyperspectral images is described in-depth in the Methods section from <a href=\"https://link.springer.com/article/10.1007/s40789-019-0252-7\" target=\"_blank\">Böhme, et al. 2019</a>. Code and documentation for `GMOdetector` is on <a href=\"https://github.com/naglemi/GMOdetector_py\" target=\"_blank\">Github</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $gmodetector_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list_name=\"$dataset_name.jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf $job_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in $data/*.hdr\n",
    "do\n",
    " if [[ \"$file\" != *'hroma'* ]]; then\n",
    "  echo \"python wrappers/analyze_sample.py \\\n",
    "--file_path $file \\\n",
    "--fluorophores ${fluorophores[*]} \\\n",
    "--min_desired_wavelength ${desired_wavelength_range[0]} \\\n",
    "--max_desired_wavelength ${desired_wavelength_range[1]} \\\n",
    "--red_channel ${FalseColor_channels[0]} \\\n",
    "--green_channel ${FalseColor_channels[1]} \\\n",
    "--blue_channel ${FalseColor_channels[2]} \\\n",
    "--red_cap ${FalseColor_caps[0]} \\\n",
    "--green_cap ${FalseColor_caps[1]} \\\n",
    "--blue_cap ${FalseColor_caps[2]} \\\n",
    "--spectral_library_path \"$spectral_library_path\" \\\n",
    "--output_dir $output_directory_full\" >> $job_list_name\n",
    " fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $job_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate test-environment\n",
    "\n",
    "if [ $parallel -eq 1 ]\n",
    "then\n",
    "    parallel -a $job_list_name >> $data/log_gmodetector.txt\n",
    "fi\n",
    "\n",
    "if [ $parallel -eq 0 ]\n",
    "then\n",
    "    bash $job_list_name >> $data/log_gmodetector.txt\n",
    "fi\n",
    "\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time regression completes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural networks to segment tissues, classify missing/contaminated explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Semantic segmentation of tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are segmented into specific plant tissues by a deep neural network of the state-of-the-art Deeplab v3 architecture <a href=\"https://arxiv.org/abs/1706.05587\" target=\"_blank\">Liang-Chieh et al., 2017</a>. The model has been trained using training sets generated with our annotation GUI Intelligent DEep Annotator for Segmentation (IDEAS, available on <a href=\"https://bitbucket.org/JialinYuan/image-annotator/src/master/\" target=\"_blank\">Bitbucket</a>, publication pending). Our branch of the Deeplab v3 repo, including a Jupyter walkthrough for training, can be found on Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is completed upstream of this notebook, which only entails analysis of test data using the latest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/downsized/segmentation_composite2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: This example image was taken from an experiment on the effects of different CIMs on cottonwood regeneration. This composite image illustrates that for every sample, tissues are segmented into stem (red), callus (blue) and shoot (green). These composite images, useful for manual inspection of results, are produced when the 'composite' option is on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Pre-processing\n",
    "##### 2.1.1.1. Normalize orientation, crop to remove labels, and resize images to 900x600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We desire for images to all be in the same orientation. At one point, the camera on the *macroPhor Array* was set to automatically detect orientation, which led to images randomly being in portrait or landscape. Here we will standardize the orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate alignment\n",
    "for filename in $data/*.jpg; do\n",
    "    #echo $filename\n",
    "    exiftool -Orientation=8 -n $filename\n",
    "    done\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f $data/*original*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script resizes images to 900x900 and then crops away top and bottom 150 pixels for a final image size of 900x600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ${cwd}/intermediates/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the `standardize_orientation.py` script was used for a situation where image rotation was attempted manually in Mac OS X but metadata was left behind, causing downstream confusion. This approach is no longer needed since we are using `exiftool` (above) to make `Orientation` in metadata consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate base\n",
    "#python standardize_orientation.py $data\n",
    "python crop.py $data\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.2. prepare test.csv file for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of all our image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data\n",
    "ls -d $PWD/* $data | grep -i \"rgb_cropped.jpg\" > test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the chroma standard from list of RGB image data to be segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed -i '/hroma/d' \"${data}/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model is deployed to perform semantic segmentation of experimental images. A list of RGB images to be segmented by the trained model is passed through the --image-list option. For each of these images, we will obtain an output mask (.png) of labeled tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `opencv`, `scipy`, `yaml` and `tensorflow` (version 1.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $deeplab_path\n",
    "conda activate deeplab\n",
    "python -W ignore inference.py --image-list \"${data}/test.csv\" >> $data/log_inference.txt\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name outputs to reflect that they are segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data\n",
    "for file in *_rgb_cropped.png; do mv -f \"$file\" \"${file%_rgb_cropped.png}_segment_cropped.png\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-expand segment outputs to same size as original RGB files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `scikit-image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate alignment\n",
    "cd $alignment_path\n",
    "python expand.py $data >> $data/log_expand.txt\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make composite images with side-by-side RGB, segmentation outputs and blended images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate test-environment\n",
    "if [ $composite -eq 1 ]\n",
    "then\n",
    "    cd $gmolabeler_path\n",
    "    python image_blender.py $data 0.75 'both' 1 180 >> $data/log_blend.txt\n",
    "fi\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Classification of contaminated/missing explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plates are cropped into sub-images for each explant and each is analyzed to determine if the explant position should be excluded from analysis due to being missing or contamination. Missing and contaminated explants are recognized using a trained Densenet model (<a href=\"https://github.com/Contamination-Classification/DenseNet\" target=\"_blank\">Huang, et al. 2018</a>). Our fork of the Densenet repository is available on <a href=\"https://arxiv.org/abs/1608.06993\" target=\"_blank\">GitHub</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Densenet.png\">\n",
    "Figure: These are four examples of contaminated explants used in the training set for this pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mode for missing explant data is automatic, prepare input file for script to detect missing explants and run this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_path=\"${data}/rgb_list.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `keras-preprocessing`, `termcolor`,  `protobuf` and `absl-py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $img_list_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running `inference.py` to detect missing or contaminated explants, the user should provide dimensions for cropping down to the grid borders. Note, these dimensions apply after the image is rescaled to 2000x2000. Default dimensions, used before the imager began to take \"off-center\" images, are (310, 515, 1750, 1610). Dimensions for cropping for the off-center images are (260, 600, 1700, 1710)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if [ $missing_explants = \"Automatic\" ]; then\n",
    "    conda activate densenet\n",
    "    echo \"Missing explants will be inferred.\"\n",
    "    cd $data\n",
    "    ls -d $PWD/* $data | grep -i \"rgb.jpg\" > rgb_list.txt\n",
    "    sed -i '/hroma/d' rgb_list.txt\n",
    "    #sed -i 's/.jpg//g' rgb_list.txt\n",
    "    #cat rgb_list.txt\n",
    "    cd $contamination_path\n",
    "    img_list_path=\"${data}/rgb_list.txt\"\n",
    "    #echo $img_list_path\n",
    "    python inference.py \\\n",
    "    --img-list=$img_list_path \\\n",
    "    --crop_dims \"(260,600,1700,1710)\" \\\n",
    "    --output_file=output.csv >> $data/log_contam.txt\n",
    "    mv -f output.csv \"${data}/output.csv\"\n",
    "    missing_explants=\"${data}/output.csv\"\n",
    "    conda deactivate\n",
    "else\n",
    "    echo \"Missing explants input manually by user, in file: \"\n",
    "    echo $missing_explants\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Alignment of RGB and hyperspectral layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the frame and angle of RGB and hyperspectral image layers, we apply a scale-invariant feature transformation (<a href=\"https://github.com/NSF-Image-alignment/ImageAlignment\" target=\"_blank\">GitHub</a>). Using a pair of standard images, a homography matrix is calculated for the necessary transformation of RGB images to align with hyperspectral images. The transformation can then be applied to large batches of images rapidly, as long as the RGB and hyperspectral cameras remain in the same positions relative to one another (as they do in the macroPhor Array platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Alignment.png\">\n",
    "Figure: To enable precise calculation of a homography matrix for transformation of RGB images to match hyperspectral images, we used images of a piece of paper with grid marks. These images are provided by the user inputs to --hyper-img and --rgb-img in the below call to the alignment script. If using a phenotyping platform other than the macroPhor Array, or using updated camera settings, these variables will need to be replaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Prepare inputs for alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to produce a csv with two columns with headers `hyper_img` and `rgb_images`. For each RGB image being transformed in batch alignment (mode 2), we can test the alignment by producing superimposed images of the transformed RGB images together with a hyperspectral layer. The hyperspectral layer can either be for a grid (fast) or can be for a layer extracted from the hyperspectral image of each channel (slow, but useful for making sure a certain homography matrix works reliably to transform a batch of images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first generate the list that will go into the column `rgb_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data\n",
    "ls | grep -i 'rgb\\.jpg' > file_list_part1.csv\n",
    "ls | grep -i 'segment_uncropped\\.png' > file_list_part2.csv\n",
    "cat file_list_part* > file_list.csv\n",
    "# sed -i '/hroma/d' file_list.csv\n",
    "cwd2=$(pwd)/\n",
    "awk -v prefix=\"$cwd2\" '{print prefix $0}' file_list.csv > temp\n",
    "mv -f temp file_list.csv\n",
    "echo 'rgb_images' | cat - file_list.csv > temp && mv -f temp file_list.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to modify the list going into the `rgb_images` column to produce the list of filenames for `hyper_img`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp file_list.csv file_list_hyper_channel.csv\n",
    "sed -i 's/_rgb.jpg/_hyperchannel.csv/g' file_list_hyper_channel.csv\n",
    "sed -i 's/rgb_images/hyper_img/g' file_list_hyper_channel.csv\n",
    "sed -i 's/_segment_uncropped.png/_hyperchannel.csv/g' file_list_hyper_channel.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bind these columns together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste --delimiters=',' file_list_hyper_channel.csv file_list.csv > rgb_and_hyper_channel_lists.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Run alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_hdr=$(ls $data | grep -i \"grid\" | grep -i \"hdr\")\n",
    "grid_jpg=$(ls $data | grep -i \"grid\" | grep -i \"rgb.jpg\")\n",
    "\n",
    "echo $grid_hdr\n",
    "echo $grid_jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate `csv` of a hyperspectral channel for the grid standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test-environment) (test-environment) Reading hyperspectral image /run/media/labgroup/Elements_9//Transformation/FAB_Dev_Genes/wk7/Fluorescent/\n",
      "Traceback (most recent call last):\n",
      "  File \"hypercube_to_csv.py\", line 40, in <module>\n",
      "    main(hdr_path = sys.argv[1],\n",
      "  File \"hypercube_to_csv.py\", line 7, in main\n",
      "    image1 = envi.open(hdr_path)\n",
      "  File \"/home/labgroup/anaconda3/envs/test-environment/lib/python3.8/site-packages/spectral/io/envi.py\", line 289, in open\n",
      "    header_path = find_file_path(file)\n",
      "  File \"/home/labgroup/anaconda3/envs/test-environment/lib/python3.8/site-packages/spectral/io/spyfile.py\", line 120, in find_file_path\n",
      "    raise FileNotFoundError(msg)\n",
      "spectral.io.spyfile.FileNotFoundError: Unable to locate file \"/run/media/labgroup/Elements_9//Transformation/FAB_Dev_Genes/wk7/Fluorescent/\". If the file exists, use its full path or place its directory in the SPECTRAL_DATA environment variable.\n",
      "(test-environment) (base) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate test-environment\n",
    "cd $alignment_path\n",
    "python hypercube_to_csv.py \\\n",
    "$data$grid_hdr \\\n",
    "700 \\\n",
    "130 \\\n",
    "$data\"hypercube_to_csv.csv\" \\\n",
    "$data\"hypercube_to_csv.jpg\"\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run alignment to generate homography matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned=$(echo $grid_jpg | sed 's/rgb/rgb_aligned/g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data\"hypercube_to_csv.csv\"\n",
    "echo $data$grid_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(alignment) (alignment) Traceback (most recent call last):\n",
      "  File \"main.py\", line 12, in <module>\n",
      "    import utils as utils\n",
      "  File \"/home/labgroup/code/ImageAlignment/utils.py\", line 20, in <module>\n",
      "    from skimage import measure\n",
      "  File \"/home/labgroup/anaconda3/envs/alignment/lib/python3.7/site-packages/skimage/measure/__init__.py\", line 2, in <module>\n",
      "    from ._marching_cubes_lewiner import marching_cubes_lewiner, marching_cubes\n",
      "  File \"/home/labgroup/anaconda3/envs/alignment/lib/python3.7/site-packages/skimage/measure/_marching_cubes_lewiner.py\", line 8, in <module>\n",
      "    from ._marching_cubes_classic import _marching_cubes_classic\n",
      "  File \"/home/labgroup/anaconda3/envs/alignment/lib/python3.7/site-packages/skimage/measure/_marching_cubes_classic.py\", line 3, in <module>\n",
      "    import scipy.ndimage as ndi\n",
      "  File \"/home/labgroup/anaconda3/envs/alignment/lib/python3.7/site-packages/scipy/ndimage/__init__.py\", line 151, in <module>\n",
      "    from .filters import *\n",
      "  File \"/home/labgroup/anaconda3/envs/alignment/lib/python3.7/site-packages/scipy/ndimage/filters.py\", line 38, in <module>\n",
      "    from . import _ni_docstrings\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 917, in get_data\n",
      "KeyboardInterrupt\n",
      "(alignment) "
     ]
    }
   ],
   "source": [
    "conda activate alignment\n",
    "cd $alignment_path\n",
    "python main.py \\\n",
    "--hyper-img $data\"hypercube_to_csv.csv\" \\\n",
    "--rgb-img $data$grid_jpg \\\n",
    "--mode 1 \\\n",
    "--image_thresh_high=120 \\\n",
    "--image_thresh_low=50 \\\n",
    "--distance=0.6 \\\n",
    "--gaussian_sigma 0.55\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display < output/$aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate alignment\n",
    "# python main.py \\\n",
    "# --hyper-img '/home/labgroup/Downloads/input/chromagrid_I5.0_F1.9_L100_131132_0_0_0_rgb.csv' \\\n",
    "# --rgb-img '/home/labgroup/Downloads/input/chromagrid_I5.0_F1.9_L100_131132_0_0_0_rgb.jpg' \\\n",
    "# --mode 1 \\\n",
    "# --image_thresh_high=120 \\\n",
    "# --image_thresh_low=50 \\\n",
    "# --distance=0.6 \\\n",
    "# --gaussian_sigma 0.57\n",
    "# conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate `csv` of hyperspectral channel for every image in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(alignment) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "hdr_files=$data/*.hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $alignment_path\n",
    "conda activate test-environment\n",
    "for hdr_file in $hdr_files\n",
    "do\n",
    " csv_file=$(sed 's/Fluorescence.hdr/hyperchannel.csv/g' <<< $hdr_file)\n",
    " csv_file=$(sed 's/.hdr/hyperchannel.csv/g' <<< $csv_file)\n",
    " csv_jpg=$(sed 's/csv/jpg/g' <<< csv_file)\n",
    " python hypercube_to_csv.py \\\n",
    " $hdr_file \\\n",
    " 500 \\\n",
    " 200 \\\n",
    " $csv_file \\\n",
    " $csv_jpg\n",
    "done\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run alignment to apply homography matrix to all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate alignment\n",
    "cd $alignment_path\n",
    "file_list_input=\"${data}/rgb_and_hyper_channel_lists.csv\"\n",
    "python main.py \\\n",
    "--hyper-img \"/run/media/labgroup/Elements_9//Transformation/FAD_Dev_Genes/wk7/Fluorescent/hypercube_to_csv.csv\" \\\n",
    "--img-csv $file_list_input \\\n",
    "--mode 2 \\\n",
    "--h_matrix_path \"output/chromagrid_I5.0_F1.9_L100LED30_125827_0_0_0_rgb_homography.npy\" >> $data/log_alignment_mode2.txt\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using this method, we should have RGB and hyperspectral images of a grid. Here, we will assume they have \"grid\" in their name and can be found in the same folder as the sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now extract a channel from the grid hypercube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, for recent \"chromagrid\" images, alignment requires the parameter `--gaussian_sigma 2.5` be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2. Generate homography matrix for alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below block generates homography matrix from a pair of an archived RGB / hyperspectral images channel layers we know to align well with these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply homography matrix to transform a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate alignment\n",
    "# cd $alignment_path\n",
    "# file_list_input=\"${data}/file_list.csv\"\n",
    "# python main.py \\\n",
    "# --img-csv $file_list_input \\\n",
    "# --mode 2 \\\n",
    "# --h_matrix_path \"output/chromagrid_I5.0_F1.9_L100_131132_0_0_0_rgb\" >> $data/log_alignment.txt\n",
    "# conda deactivate\n",
    "# conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below commented-out part is for if we are re-doing alignment every time instead of taking a standard pair of images that align well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned=$(echo $grid_jpg | sed 's/rgb/rgb_aligned/g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate alignment\n",
    "# python main.py \\\n",
    "# --hyper-img $data\"hypercube_to_csv.csv\" \\\n",
    "# --rgb-img $data$grid_jpg \\\n",
    "# --mode 1 \\\n",
    "# --image_thresh_high=120 \\\n",
    "# --image_thresh_low=50 \\\n",
    "# --distance=0.6 \\\n",
    "# --gaussian_sigma 0.649\n",
    "# conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display < $alignment_path/output/$aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate alignment\n",
    "# cd $alignment_path\n",
    "# file_list_input=\"${data}/file_list.csv\"\n",
    "# python main.py \\\n",
    "# --hyper-img $data\"hypercube_to_csv.csv\" \\\n",
    "# --rgb-img $data$grid_jpg \\\n",
    "# --img-csv $file_list_input \\\n",
    "# --mode 2 \\\n",
    "# --image_thresh_high=120 \\\n",
    "# --image_thresh_low=50 \\\n",
    "# --distance=0.6 \\\n",
    "# --gaussian_sigma 0.57 >> $data/log_align.txt\n",
    "# conda deactivate\n",
    "# conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-analyze deep segmentation and regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts in the <a href=\"https://github.com/naglemi/GMOlabeler\" target=\"_blank\">GMOlabeler repository</a> are used to cross-reference results from deep segmentation of RGB images and regression of hyperspectral imaging, apply thresholding parameters to classify tissues as transgenic or escapes, and produce plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/GMOlabeler.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: The various steps of data processing in GMOlabeler are illustrated for an example explant from an experiment on CIM optimization for cottonwood. Images of plates are cropped to a sub-image for each explant. RGB segmentation results and hyperspectral regression results are cross-referenced to calculate fluorecent proteins in specific tissues and infer whether these tissues are transgenic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Prepare sample datasheet input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input file we will use for making plots. This file contains paths to CLS results, RGB images, and hyperspectral images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $data$aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "cd \"${cwd}/intermediates/\"\n",
    "Rscript pre_label.R \\\n",
    "-r \"${data}/\" \\\n",
    "-R \"${output_directory_prefix}\" \\\n",
    "-i 1 \\\n",
    "-d $datestamp\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. Cross-reference RGB and hyperspectral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On 1/11/20, we altered `gmolabeler` to accept user-defined borders of the grid box, rather than hardcoding these borders in for specific grids with 12 or 20 explants. Thus, if providing `grid_borders`, `grid` can be left as `None`, or vice versa. To determine the borders, open the *aligned* grid file in a GUI like GIMP or Microsoft Paint and use the crosshairs to find the pixel positions of each border. These are then provided in order \"left right bottom top\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE THE CHANGE HERE for FAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old=/run/media/labgroup/Elements_9//Transformation/FAD_Dev_Genes/wk7/Fluorescent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_grid=$(ls $data_old | grep -i \"grid\" | grep -i \"rgb_processed.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aligned_grid=$(ls $data | grep -i \"grid\" | grep -i \"rgb_processed.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $aligned_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on grid copping parameters:\n",
    "- Submit a space-delimited string with parameters for borders of grid as \"left right bottom top\"\n",
    "- For FAA wk3, use parameters \"139 1580 1250 312\"\n",
    "- For FAA wk7 and FAD wk7, use \"156 1600 1280 335\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "cd $gmolabeler_path\n",
    "python main.py \\\n",
    "\"${data}/samples_pre_labeling.csv\" \\\n",
    "$data_old$aligned_grid \\\n",
    "$reporter_threshold \\\n",
    "$reporter \\\n",
    "$grid \\\n",
    "\"hdf\" \\\n",
    "$gmolabeler_path \\\n",
    "\"156 1600 1280 335\"\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3. Calculate sums of statistics over combined segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in all regenerated tissue (callus + shoot) as well as all tissue (including stem as well). We will calculate aggregate statistics over these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "Rscript calculate_sum_stats_over_combined_segments.R \\\n",
    "--output_dir \"${gmolabeler_path}/output/\" \\\n",
    "--datapath \"${data_folder}/\"\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4. Make plots of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate gmolabeler\n",
    "cd $gmolabeler_path\n",
    "Rscript grid_item_plots.R \\\n",
    "-d \"${data_folder}/\" \\\n",
    "-r \"$randomization_datasheet\" \\\n",
    "-p $pixel_threshold \\\n",
    "-v categorical \\\n",
    "-m 1 \\\n",
    "-M $missing_explants \\\n",
    "-g $grid \\\n",
    "--sort 1 \\\n",
    "--height $height \\\n",
    "--width $width\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Email plots to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1. ZIP results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"${gmolabeler_path}/plots${data_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"${gmolabeler_path}/plots/${data_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f ./plants_over_plates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo ${gmolabeler_path}/output/${data_folder}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp \"${gmolabeler_path}/output/${data_folder}/plants_over_plates.csv\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp \"${gmolabeler_path}/output/${data_folder}/stats_with_sums_over_tissues.csv\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f Rplots.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This messy substitution is explained here: https://superuser.com/questions/1068031/replace-backslash-with-forward-slash-in-a-variable-in-bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_Compress=\"${data_folder////-}.zip\"\n",
    "data_folder_Compress=${data_folder_Compress#?};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $timepoint\n",
    "zip -r $data_folder_Compress ./*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2. Write email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration=$(( SECONDS - start ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://unix.stackexchange.com/questions/53841/how-to-use-a-timer-in-bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f \"${gmolabeler_path}/email_to_send.txt\"\n",
    "cp \"${gmolabeler_path}/email_to_send_template.txt\" \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "echo \"Number of samples run: \" >> \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat \"${data}/test.csv\" | wc -l >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "echo \"\" >> \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (( $SECONDS > 3600 )) ; then\n",
    "    let \"hours=SECONDS/3600\"\n",
    "    let \"minutes=(SECONDS%3600)/60\"\n",
    "    let \"seconds=(SECONDS%3600)%60\"\n",
    "    echo \"Completed in $hours hour(s), $minutes minute(s) and $seconds second(s)\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "elif (( $SECONDS > 60 )) ; then\n",
    "    let \"minutes=(SECONDS%3600)/60\"\n",
    "    let \"seconds=(SECONDS%3600)%60\"\n",
    "    echo \"Completed in $minutes minute(s) and $seconds second(s)\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "else\n",
    "    echo \"Completed in $SECONDS seconds\" >> \"${gmolabeler_path}/email_to_send.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"\" >> \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3. Send email with results to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail -a $data_folder_Compress -s $data_folder $email < \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du -sh $data_folder_Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat \"${gmolabeler_path}/email_to_send.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time analysis ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
